{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qj2CSyA7pDwFm5svqU9uEWXC-e6lgLh1?usp=sharing)"
      ],
      "metadata": {
        "id": "vJez3oKnx4SW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push keras models to Huggingface hub\n",
        "\n",
        "- https://huggingface.co/login\n",
        "- https://huggingface.co/docs/hub/oauth\n",
        "- https://huggingface.co/models"
      ],
      "metadata": {
        "id": "D_pvsktNnsNO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3G09mlaF4Mt"
      },
      "source": [
        "%%capture\n",
        "! pip install git+https://github.com/huggingface/huggingface_hub.git@main\n",
        "! sudo apt -qq install git-lfs\n",
        "! git config --global credential.helper store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUZWRnP4Jfef"
      },
      "source": [
        "## Make sure you're logged in to Hugging Face CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8pDwbNJe4F"
      },
      "source": [
        "! huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcuLdv9PJE0T"
      },
      "source": [
        "# Simple Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laylRQihJY70"
      },
      "source": [
        "### Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52RAAkFOJEnj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from huggingface_hub import push_to_hub_keras\n",
        "\n",
        "inputs = keras.Input(shape=(8, ), name='input_layer')\n",
        "l_1 = layers.Dense(4, activation='relu', name='layer_1')(inputs)\n",
        "l_2 = layers.Dense(4, activation='relu', name='layer_2')(l_1)\n",
        "outputs = layers.Dense(1, name='output_layer')(l_2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')\n",
        "model.summary()\n",
        "model.build((None, 8))\n",
        "push_to_hub_keras(model, 'keras-dummy-functional-demo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load from pretrained model hub"
      ],
      "metadata": {
        "id": "3v0-UyL3t4-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import from_pretrained_keras\n",
        "\n",
        "model = from_pretrained_keras(\"keras-io/mobile-vit-xxs\")\n",
        "model.summary()\n",
        "push_to_hub_keras(model, 'keras-mobile-vit-xxs')"
      ],
      "metadata": {
        "id": "DwcDBgqArWYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I90IsKHqJu-J"
      },
      "source": [
        "# Complete Example\n",
        "\n",
        "This is a more complete example of training a denoising autoencoder (taken from [keras-io/examples](https://github.com/keras-team/keras-io/blob/master/examples/vision/autoencoder.py))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_8MBueYGBmj"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm4X6gFgHC66"
      },
      "source": [
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "\n",
        "    array = array.astype(\"float32\") / 255.0\n",
        "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "    return array\n",
        "\n",
        "\n",
        "def noise(array):\n",
        "    \"\"\"\n",
        "    Adds random noise to each image in the supplied array.\n",
        "    \"\"\"\n",
        "\n",
        "    noise_factor = 0.4\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def display(array1, array2):\n",
        "    \"\"\"\n",
        "    Displays ten random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    n = 10\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image1.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(image2.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoS4NeP7HF32"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj6X74kcHFil"
      },
      "source": [
        "# Since we only need images from the dataset to encode and decode, we\n",
        "# won't use the labels.\n",
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(train_data)\n",
        "noisy_test_data = noise(test_data)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display(train_data, noisy_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFSZIVe5HJmm"
      },
      "source": [
        "## Build the Autoencoder\n",
        "\n",
        "We are going to use the Functional API to build our convolutional autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avlOaWBbHPAI"
      },
      "source": [
        "input = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZh9PRLHcIV"
      },
      "source": [
        "## Train the Autoencoder on Noisy Data\n",
        "\n",
        "We want our autoencoder to learn how to denoise the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUn1KeSwHeVo"
      },
      "source": [
        "autoencoder.fit(\n",
        "    x=noisy_train_data,\n",
        "    y=train_data,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_test_data, test_data),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLA6vmxwHweS"
      },
      "source": [
        "## Make Predictions\n",
        "\n",
        "Let's now predict on the noisy data and display the results of our autoencoder.\n",
        "Notice how the autoencoder does an amazing job at removing the noise from the\n",
        "input images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6cCFrD-HuwA"
      },
      "source": [
        "predictions = autoencoder.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDRFtPwnGLcT"
      },
      "source": [
        "## Push Autoencoder to Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTMsNpmIGOC"
      },
      "source": [
        "from huggingface_hub import push_to_hub_keras\n",
        "\n",
        "push_to_hub_keras(autoencoder, 'autoencoder-keras-mnist-demo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klODQdTVE6qe"
      },
      "source": [
        "## Reload from hub and make predictions!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(image, title='Image'):\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FrtqFrxe6upn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_model = from_pretrained_keras('aromo17/autoencoder-keras-mnist-demo')\n",
        "input_image = noisy_test_data[0]\n",
        "pred = reloaded_model.keras_api([input_image])\n",
        "\n",
        "display_image(input_image, title='noisy')\n",
        "display_image(pred[0], title='generated')"
      ],
      "metadata": {
        "id": "dl5S2Gis6Hmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}