{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33aef95c",
      "metadata": {
        "id": "33aef95c"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1XdKONYykHY7Z60uMFF0i2Y0WYJNbIYsi?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad62796",
      "metadata": {
        "id": "3ad62796"
      },
      "source": [
        "# Introduction to Computer Vision with OpenCV in Python\n",
        "\n",
        "https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CV_with_OpenCV.ipynb\n",
        "\n",
        "OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in commercial products. It has C++, Python, and Java interfaces and supports Windows, Linux, Mac OS, iOS, and Android."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opencv-python"
      ],
      "metadata": {
        "id": "aIo4ed76azxB"
      },
      "id": "aIo4ed76azxB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ee52c0c",
      "metadata": {
        "id": "1ee52c0c"
      },
      "source": [
        "\n",
        "# Reading, Writing, and Displaying Images\n",
        "\n",
        "## Reading Images\n",
        "\n",
        "OpenCV allows you to read images in various formats. The most common method is using `cv2.imread()`. This function loads an image from a file and returns it as a NumPy array. If the image cannot be read (because of missing file, improper permissions, unsupported or invalid format), this function returns an empty matrix.\n",
        "\n",
        "- Syntax: `cv2.imread(path, flag)`\n",
        "- Flags:\n",
        "  - `cv2.IMREAD_COLOR` or `1`: Loads a color image. Any transparency is ignored (default).\n",
        "  - `cv2.IMREAD_GRAYSCALE` or `0`: Loads image in grayscale mode.\n",
        "  - `cv2.IMREAD_UNCHANGED` or `-1`: Loads image as such including alpha channel.\n",
        "  \n",
        "In OpenCV, when you load an image using `cv2.imread()`, the image is automatically read in BGR (Blue, Green, Red) format by default. This is different from the RGB (Red, Green, Blue) format that is commonly used in many other image processing libraries and applications.\n",
        "\n",
        "The difference between these two formats is the order of color channels:\n",
        "\n",
        "- **BGR**: The blue channel comes first, followed by green, and then red.\n",
        "- **RGB**: The red channel comes first, followed by green, and then blue.\n",
        "\n",
        "```python\n",
        "# Convert the BGR image to RGB\n",
        "image_rgb = cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b43623",
      "metadata": {
        "id": "82b43623"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download an image\n",
        "url = 'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n",
        "urllib.request.urlretrieve(url, \"sample.png\")\n",
        "\n",
        "\n",
        "# Path to the image\n",
        "image_path = \"sample.png\"\n",
        "\n",
        "# Read the image in color mode\n",
        "image_color = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Read the image in grayscale mode\n",
        "image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Transform to RGB\n",
        "image_rgb = cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b5c110",
      "metadata": {
        "id": "24b5c110"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
        "\n",
        "# Plot original BGR image\n",
        "axes[0].imshow(image_color)  # Convert BGR to RGB for correct color representation in matplotlib\n",
        "axes[0].set_title(\"BGR Image\")\n",
        "axes[0].axis('off')  # Hide axis\n",
        "\n",
        "# Plot grayscale image\n",
        "axes[1].imshow(image_gray, cmap='gray')  # Grayscale image\n",
        "axes[1].set_title(\"Grayscale Image\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Plot RGB image\n",
        "axes[2].imshow(image_rgb)  # RGB image\n",
        "axes[2].set_title(\"RGB Image\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c9c988",
      "metadata": {
        "id": "b4c9c988"
      },
      "source": [
        "## Writing Images\n",
        "\n",
        "Saving an image in OpenCV is accomplished using the `cv2.imwrite()` function. It saves an image to a specified file. The image format is chosen based on the filename extension.\n",
        "\n",
        "- Syntax: `cv2.imwrite(filename, img, params)`\n",
        "- Parameters:\n",
        "  - `filename`: String representing the file name.\n",
        "  - `img`: Image to be saved.\n",
        "  - `params`: Optional parameters.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "# Save the grayscale image\n",
        "cv2.imwrite(\"path_to_save_gray_image.jpg\", image_gray)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b376323-789c-4fc0-873e-747719dcb53d",
      "metadata": {
        "id": "6b376323-789c-4fc0-873e-747719dcb53d"
      },
      "source": [
        "# Basic Image Manipulation with OpenCV\n",
        "\n",
        "In this section, we will explore basic image manipulation techniques such as resizing, rotating, and cropping images using OpenCV. These operations are fundamental in many computer vision tasks.\n",
        "\n",
        "## Resizing Images\n",
        "\n",
        "Resizing is one of the most common operations. It's used to change the dimensions of an image. In OpenCV, `cv2.resize()` function is used for this purpose.\n",
        "\n",
        "- Syntax: `cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])`\n",
        "- Parameters:\n",
        "  - `src`: Input image.\n",
        "  - `dsize`: Desired size for the output image.\n",
        "  - `fx` and `fy`: Scale factors along the horizontal and vertical axes respectively.\n",
        "  - `interpolation`: Interpolation method. Common methods include `cv2.INTER_LINEAR`, `cv2.INTER_NEAREST`, `cv2.INTER_AREA`, `cv2.INTER_CUBIC`, and `cv2.INTER_LANCZOS4`. The choice of interpolation method affects the quality and processing time.\n",
        "\n",
        "Interpolation methods:\n",
        "- `cv2.INTER_LINEAR`: This is a good default choice for both upsizing and downsizing.\n",
        "- `cv2.INTER_NEAREST`: Fastest but may produce jagged edges.\n",
        "- `cv2.INTER_AREA`: Recommended for downsizing as it may produce moir√©-free results.\n",
        "- `cv2.INTER_CUBIC`: Slower but more effective for upsizing.\n",
        "- `cv2.INTER_LANCZOS4`: Offers high-quality results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0782011c-28ab-4062-8c36-9e4002bb644f",
      "metadata": {
        "id": "0782011c-28ab-4062-8c36-9e4002bb644f"
      },
      "outputs": [],
      "source": [
        "resized_image_1 = cv2.resize(image_rgb, (300, 300), interpolation=cv2.INTER_LINEAR)\n",
        "print(f'image shape: {resized_image_1.shape}')\n",
        "plt.imshow(resized_image_1)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3536eb-c519-41f3-9b7e-3fddfd89349f",
      "metadata": {
        "id": "bc3536eb-c519-41f3-9b7e-3fddfd89349f"
      },
      "outputs": [],
      "source": [
        "resized_image_2 = cv2.resize(image_rgb, (0, 0), fx=0.5, fy=0.5)\n",
        "print(f'image shape: {resized_image_2.shape}')\n",
        "plt.imshow(resized_image_2)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c11982-6e01-491d-a1b9-327723bf88d8",
      "metadata": {
        "id": "d1c11982-6e01-491d-a1b9-327723bf88d8"
      },
      "source": [
        "## Cropping Images\n",
        "\n",
        "Cropping involves cutting out a portion of an image. In OpenCV, this can be done by slicing the NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab09ab2",
      "metadata": {
        "id": "6ab09ab2"
      },
      "outputs": [],
      "source": [
        "# Crop the image\n",
        "cropped_image = image_rgb[50:250, 100:350]  # Crop from x=100, y=50 to x=300, y=200\n",
        "\n",
        "plt.imshow(cropped_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea375c7d-1366-4981-95b7-7487167c3a78",
      "metadata": {
        "id": "ea375c7d-1366-4981-95b7-7487167c3a78"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "# Define the crop box coordinates (x, y, width, height)\n",
        "crop_box = (100, 100, 200, 200)  # (x, y, width, height)\n",
        "\n",
        "# Create a Rectangle patch\n",
        "rect = patches.Rectangle((crop_box[0], crop_box[1]), crop_box[2], crop_box[3], linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "# Plot the original image and the rectangle\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(image_rgb)\n",
        "ax.add_patch(rect)\n",
        "plt.show()\n",
        "\n",
        "# Define the box to crop\n",
        "# Note: OpenCV uses the format (y, y+h, x, x+w) for cropping\n",
        "cropped_image = image_rgb[crop_box[1]:crop_box[1] + crop_box[3], crop_box[0]:crop_box[0] + crop_box[2]]\n",
        "\n",
        "# Display the cropped image\n",
        "plt.imshow(cropped_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321b0f78-471b-472a-afde-45ef068068d3",
      "metadata": {
        "id": "321b0f78-471b-472a-afde-45ef068068d3"
      },
      "source": [
        "# Image Thresholding with OpenCV\n",
        "\n",
        "Image thresholding is a simple, yet effective, way of partitioning an image into a foreground and background. This is done by selecting a threshold value, and then classifying all pixels above this threshold as belonging to the foreground (usually white) and all pixels below this threshold as belonging to the background (usually black).\n",
        "\n",
        "## Basic Thresholding\n",
        "\n",
        "The most basic form of thresholding applies a fixed level threshold to each pixel. The general form of the thresholding operation on an image \\( f(x, y) \\) can be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        " g(x, y) = \\begin{cases}\n",
        "\\text{maxVal} & \\text{if } f(x, y) > \\text{threshold} \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "In OpenCV, this is implemented using the `cv2.threshold` function.\n",
        "\n",
        "- Syntax: `retval, dst = cv2.threshold(src, thresh, maxval, type)`\n",
        "- Parameters:\n",
        "  - `src`: Input image (grayscale).\n",
        "  - `thresh`: Threshold value.\n",
        "  - `maxval`: Maximum value to use with the binary thresholding operations.\n",
        "  - `type`: Thresholding type (e.g., `cv2.THRESH_BINARY`, `cv2.THRESH_BINARY_INV`, etc.)\n",
        "\n",
        "Example of basic thresholding:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d313b10e-8f4b-4b16-9354-d3c72c616ac8",
      "metadata": {
        "id": "d313b10e-8f4b-4b16-9354-d3c72c616ac8"
      },
      "outputs": [],
      "source": [
        "# Convert to grayscale\n",
        "gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply basic thresholding\n",
        "ret, thresh_basic = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "plt.imshow(thresh_basic, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ea8385-981a-41bc-81fa-9cdac9f59766",
      "metadata": {
        "id": "81ea8385-981a-41bc-81fa-9cdac9f59766"
      },
      "source": [
        "## Adaptive Thresholding\n",
        "\n",
        "Adaptive thresholding changes the threshold value based on the image characteristics. In adaptive thresholding, the threshold value is determined for smaller regions. This leads to different threshold values for different regions of the same image, which is useful in case of varying lighting conditions across the image.\n",
        "\n",
        "OpenCV provides `cv2.adaptiveThreshold` for this purpose.\n",
        "\n",
        "- Syntax: `dst = cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)`\n",
        "- Parameters:\n",
        "  - `maxValue`: Non-zero value assigned to the pixels for which the condition is satisfied.\n",
        "  - `adaptiveMethod`: Adaptive method decides how the threshold value is calculated (e.g., `cv2.ADAPTIVE_THRESH_MEAN_C`, `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
        "    1. **`cv2.ADAPTIVE_THRESH_MEAN_C`:**\n",
        "       - This method calculates the mean of the `blockSize` x `blockSize` neighborhood of each pixel (excluding the pixel itself) and subtracts `C` from this mean to determine the pixel's threshold.\n",
        "       - It's useful for images with a relatively uniform brightness, where the goal is to highlight the central tendencies in local areas of the image.\n",
        "\n",
        "    2. **`cv2.ADAPTIVE_THRESH_GAUSSIAN_C`:**\n",
        "      - This method calculates the weighted sum of the `blockSize` x `blockSize` neighborhood, where the weights are a Gaussian window, and subtracts `C` from this sum to determine the pixel's threshold.\n",
        "      - It's more sophisticated and considers the spatial distribution of pixel intensities, making it more suitable for images with varying illumination conditions.\n",
        "\n",
        "  - `blockSize`: Size of a pixel neighborhood that is used to calculate a threshold value. It must be an odd number greater than 1\n",
        "    - A larger `blockSize` considers a larger area for local thresholding, which can be useful for images with more significant variations in lighting. However, it might also reduce the detail in the thresholded image.\n",
        "  - `C`: Constant subtracted from the mean or weighted mean.\n",
        "      - `C` allows fine-tuning of the thresholding. It serves as a bias in the threshold calculation.\n",
        "      - If `C` is positive, it makes the algorithm more aggressive, producing a more contrasted image by making the dark regions darker.\n",
        "      - If `C` is negative, it makes the algorithm less sensitive, which might retain more details but could also include more noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676e9ed8-5df3-4f55-be3c-7a6d6d2ef99c",
      "metadata": {
        "id": "676e9ed8-5df3-4f55-be3c-7a6d6d2ef99c"
      },
      "outputs": [],
      "source": [
        "adaptive_thresh = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "plt.imshow(adaptive_thresh, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4697826-ac34-4ff4-8eba-e102bd0184e3",
      "metadata": {
        "id": "f4697826-ac34-4ff4-8eba-e102bd0184e3"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, widgets\n",
        "\n",
        "def interactive_thresholding(thresh_type, threshold, block_size, C):\n",
        "    if thresh_type == 'Binary':\n",
        "        _, th = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n",
        "    elif thresh_type == 'Adaptive Mean':\n",
        "        th = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, C)\n",
        "    elif thresh_type == 'Adaptive Gaussian':\n",
        "        th = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, C)\n",
        "\n",
        "    plt.imshow(th, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "interact(interactive_thresholding,\n",
        "         thresh_type=widgets.Dropdown(options=['Binary', 'Adaptive Mean', 'Adaptive Gaussian'], value='Binary', description='Threshold Type:'),\n",
        "         threshold=widgets.IntSlider(min=0, max=255, step=1, value=127, description='Threshold:'),\n",
        "         block_size=widgets.IntSlider(min=3, max=21, step=2, value=11, description='Block Size:', disabled=False),\n",
        "         C=widgets.IntSlider(min=0, max=10, value=2, description='C Value:')\n",
        "        );\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b923e1-b6ca-46cd-b8dd-706796abb835",
      "metadata": {
        "id": "a2b923e1-b6ca-46cd-b8dd-706796abb835"
      },
      "source": [
        "# Histogram Equalization in OpenCV\n",
        "\n",
        "Histogram equalization is a technique for adjusting image intensities to enhance contrast. It's particularly useful in images with backgrounds and foregrounds that are both bright or both dark.\n",
        "\n",
        "## Understanding Histograms in Image Processing\n",
        "\n",
        "A histogram represents the distribution of pixel intensities (whether in grayscale or color channels) in an image. It plots the number of pixels for each intensity value.\n",
        "\n",
        "### Displaying a Histogram for a Real Image\n",
        "\n",
        "First, let's see how to display a histogram for a grayscale image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a7f227-29bc-451e-b040-1495cbcbf410",
      "metadata": {
        "id": "88a7f227-29bc-451e-b040-1495cbcbf410"
      },
      "outputs": [],
      "source": [
        "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Normal_posteroanterior_%28PA%29_chest_radiograph_%28X-ray%29.jpg/560px-Normal_posteroanterior_%28PA%29_chest_radiograph_%28X-ray%29.jpg'\n",
        "image_path = \"x-ray.jpeg\"\n",
        "urllib.request.urlretrieve(url, image_path)\n",
        "\n",
        "# Load an image in grayscale\n",
        "gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Calculate the histogram\n",
        "hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
        "\n",
        "\n",
        "# Plot the image and its histogram\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Display the image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.title(\"Grayscale Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Display the histogram\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist)\n",
        "plt.title(\"Grayscale Histogram\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"# of Pixels\")\n",
        "plt.xlim([0, 256])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e201ea6b-5a7e-49c9-a0ad-8acf0c3dc53a",
      "metadata": {
        "id": "e201ea6b-5a7e-49c9-a0ad-8acf0c3dc53a"
      },
      "source": [
        "## Histogram Equalization\n",
        "\n",
        "Histogram equalization improves the contrast of an image by stretching out the intensity range.\n",
        "\n",
        "### Concept\n",
        "\n",
        "The idea is to spread out the most frequent intensity values, i.e., to stretch the histogram horizontally on both sides, making the dark pixels darker and the bright pixels brighter. This often increases the global contrast of many images, especially when the usable data of the image is represented by close contrast values.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "Given a grayscale image \\( I \\), histogram equalization works by first calculating the normalized histogram \\( H(v) \\) for each intensity level \\( v \\). Then, a cumulative distribution function (CDF) is computed, which is essentially a cumulative sum of the normalized histogram values:\n",
        "\n",
        "\\begin{equation}\n",
        "CDF(v) = \\sum_{i=0}^{v} H(i)\n",
        "\\end{equation}\n",
        "\n",
        "The equalized image \\( I_{eq} \\) is obtained by mapping each pixel intensity \\( v \\) in the original image to a new intensity level using the CDF:\n",
        "\n",
        "\\begin{equation}\n",
        "I_{eq}(x, y) = \\text{round} \\left( \\frac{CDF(I(x, y)) - \\text{min}(CDF)}{\\text{max}(CDF) - \\text{min}(CDF)} \\times 255 \\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a923cf6-28e2-469e-b000-145150839740",
      "metadata": {
        "id": "4a923cf6-28e2-469e-b000-145150839740"
      },
      "outputs": [],
      "source": [
        "equalized_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "# Calculate histograms\n",
        "hist_original = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
        "hist_equalized = cv2.calcHist([equalized_image], [0], None, [256], [0, 256])\n",
        "\n",
        "# Create a 2x2 subplot\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Display the original image\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.title(\"Original Grayscale Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Display the histogram for the original image\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(hist_original)\n",
        "plt.title(\"Histogram of Original Image\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"# of Pixels\")\n",
        "plt.xlim([0, 256])\n",
        "\n",
        "# Display the equalized image\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(equalized_image, cmap='gray')\n",
        "plt.title(\"Histogram Equalized Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Display the histogram for the equalized image\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(hist_equalized)\n",
        "plt.title(\"Histogram of Equalized Image\")\n",
        "plt.xlabel(\"Bins\")\n",
        "plt.ylabel(\"# of Pixels\")\n",
        "plt.xlim([0, 256])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d3456e-5424-4093-856d-f6b04f3e6059",
      "metadata": {
        "id": "39d3456e-5424-4093-856d-f6b04f3e6059"
      },
      "source": [
        "## CLAHE: Contrast Limited Adaptive Histogram Equalization\n",
        "\n",
        "CLAHE is a variant of adaptive histogram equalization in which the image is divided into small blocks called \"tiles\" (e.g., 8x8). Then, histogram equalization is applied to each of these blocks separately. This method prevents over-amplification of noise that is typical in the standard histogram equalization technique.\n",
        "\n",
        "### Key Features of CLAHE:\n",
        "- **Local Contrast Enhancement:** Unlike standard histogram equalization, which applies a global contrast enhancement, CLAHE enhances the contrast locally.\n",
        "- **Contrast Limiting:** To prevent noise amplification, CLAHE applies contrast limiting. If any histogram bin is above the specified contrast limit, those pixels are clipped and distributed uniformly to other bins before applying histogram equalization.\n",
        "\n",
        "### Mathematical Overview:\n",
        "CLAHE operates similarly to adaptive histogram equalization but with an additional contrast limiting step. After computing the histogram for each block, the histogram is clipped at a predefined value, ensuring that the enhancement doesn‚Äôt increase the noise.\n",
        "\n",
        "### Applying CLAHE in OpenCV:\n",
        "OpenCV provides the `createCLAHE` function to apply CLAHE.\n",
        "\n",
        "- **clipLimit**: This parameter is used to limit the contrast amplification. It is a threshold for contrast limiting. Higher values give more contrast. The clip limit prevents noise amplification by limiting the contrast of tiles where the histogram has a high peak.\n",
        "\n",
        "- **tileGridSize**: This parameter defines the size of the grid for the histogram equalization. It is a tuple (tileGridSizeX, tileGridSizeY) that specifies the number of tiles in the row and column. the image will be divided into an nxn grid, and CLAHE will be applied to each grid cell individually.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba32fcbf-747a-4bbc-a8a5-1ced69db7e7c",
      "metadata": {
        "id": "ba32fcbf-747a-4bbc-a8a5-1ced69db7e7c"
      },
      "outputs": [],
      "source": [
        "# Create a CLAHE object\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\n",
        "# Apply CLAHE to the grayscale image\n",
        "clahe_image = clahe.apply(gray_image)\n",
        "\n",
        "# Display the original and CLAHE-enhanced image\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(121), plt.imshow(gray_image, cmap='gray'), plt.title('Original Image')\n",
        "plt.subplot(122), plt.imshow(clahe_image, cmap='gray'), plt.title('CLAHE Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d754aef5-14c4-4cfd-ac46-637f94a8bd2e",
      "metadata": {
        "id": "d754aef5-14c4-4cfd-ac46-637f94a8bd2e"
      },
      "outputs": [],
      "source": [
        "def view_clahe(clip_limit, tile_grid_size):\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_grid_size, tile_grid_size))\n",
        "    clahe_image = clahe.apply(gray_image)\n",
        "\n",
        "    plt.imshow(clahe_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "interact(view_clahe,\n",
        "         clip_limit=widgets.FloatSlider(min=1, max=5, step=0.1, value=2),\n",
        "         tile_grid_size=widgets.IntSlider(min=1, max=16, step=1, value=8));\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}