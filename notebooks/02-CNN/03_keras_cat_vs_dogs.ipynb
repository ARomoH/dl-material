{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XLQX0nW7AiG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17q49L3fPuIzmCZQ77RJQjZWyvW9p3M_I?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xMF893leGzR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjtiHxkH7AiJ"
      },
      "source": [
        "# Introduction to Tensorflow  Dataset\n",
        "\n",
        "https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/cat_vs_dogs.ipynb\n",
        "\n",
        "[Tensorflow tf.data.Dataset tutorial](https://www.tensorflow.org/guide/data)\n",
        "\n",
        "TensorFlow's tf.data API, which provides a convenient way to create efficient input pipelines for training and evaluation of machine learning models. `tf.data.Dataset` is an abstraction of a\n",
        "sequence of elements.\n",
        "\n",
        "The first step to using the tf.data API is creating a Dataset object. Datasets can be created from various sources, including in-memory data, files, or by generating data on-the-fly.\n",
        "\n",
        "For this example, let's create a dataset from an in-memory NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMIJerCu7AiJ",
        "outputId": "289a852a-4b17-4496-d8e6-51fd8bcceacd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-22 14:28:25.095956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-03-22 14:28:25.096758: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "# Create a sample NumPy array\n",
        "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Create a tf.data Dataset from the NumPy array\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NBwNLOx7AiK"
      },
      "source": [
        "The `Dataset` object is a Python iterable. This makes it possible to consume its\n",
        "elements using a for loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x2FbOps7AiK",
        "outputId": "b929888f-85df-4ca6-f3a1-9538354e6c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "for elem in dataset:\n",
        "      print(elem.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCCf9w5I7AiK"
      },
      "source": [
        "Now that we have a dataset, we can apply various transformations to prepare the data for training. Some common transformations include shuffling, batching, and repeating.\n",
        "\n",
        "**Shuffle**\n",
        "\n",
        "Randomly shuffles the elements of this dataset.\n",
        "\n",
        "This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg4KeJfi7AiL",
        "outputId": "cafab87e-394d-44bd-a020-eef58bcd7975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "4\n",
            "3\n",
            "6\n",
            "5\n",
            "7\n",
            "9\n",
            "10\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "buffer_size = 2\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "\n",
        "for elem in dataset:\n",
        "      print(elem.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfbS-bG77AiL"
      },
      "source": [
        "**Batch**\n",
        "\n",
        "Combines consecutive elements of this dataset into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAkcShrV7AiL",
        "outputId": "0603693f-04de-46f3-c07f-54f216bd5946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 1]\n",
            "[3 5]\n",
            "[7 6]\n",
            "[ 4 10]\n",
            "[8 9]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2\n",
        "\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "for elem in dataset:\n",
        "      print(elem.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv11OWUl7AiL"
      },
      "source": [
        "In addition to using in-memory data, the `tf.data` API can also read data from files, such as images or text files. For example, let's create a dataset of text lines from a sample file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMRjRQNu7AiM",
        "outputId": "1723f6f2-e733-4751-d8b2-35ac8c2898fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'This is a sample text file.'\n",
            "b'Each line represents an element in the dataset.'\n",
            "b'We can apply various transformations to the data.'\n",
            "b'This makes it easy to prepare data for training.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-22 14:36:27.556329: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2023-03-22 14:36:27.558400: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        }
      ],
      "source": [
        "# Create a sample text file\n",
        "with open(\"sample.txt\", \"w\") as f:\n",
        "    f.write(\"This is a sample text file.\\n\")\n",
        "    f.write(\"Each line represents an element in the dataset.\\n\")\n",
        "    f.write(\"We can apply various transformations to the data.\\n\")\n",
        "    f.write(\"This makes it easy to prepare data for training.\\n\")\n",
        "\n",
        "# Create a tf.data Dataset from the text file\n",
        "dataset = tf.data.TextLineDataset(\"sample.txt\")\n",
        "for elem in dataset:\n",
        "      print(elem.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XStkvLKC7AiM"
      },
      "source": [
        "To preprocess the text data, we can apply a map function to the dataset. This allows us to perform arbitrary operations on each element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIs35JTf7AiM",
        "outputId": "c0160dc0-2270-49d0-acae-7e123cdfec3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'this is a sample text file.'\n",
            "b'each line represents an element in the dataset.'\n",
            "b'we can apply various transformations to the data.'\n",
            "b'this makes it easy to prepare data for training.'\n"
          ]
        }
      ],
      "source": [
        "# Define a preprocessing function\n",
        "def preprocess_text(line):\n",
        "    line = tf.strings.lower(line)\n",
        "    line = tf.strings.strip(line)\n",
        "    return line\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "dataset = dataset.map(preprocess_text)\n",
        "\n",
        "for elem in dataset:\n",
        "      print(elem.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdtaU2Cc7AiM"
      },
      "source": [
        "# Cat vs dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpljkU2seGzT"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "dataset = dataset['train']\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "print(f'number of images:{size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUfigIhzeGzU"
      },
      "source": [
        "We need all images to be the same size, we can use [`resize`](https://www.tensorflow.org/api_docs/python/tf/image/resize):\n",
        "\n",
        "```python\n",
        "tf.image.resize(\n",
        "    images, size, method=ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
        "    antialias=False, name=None\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-HXP86oeGzV"
      },
      "outputs": [],
      "source": [
        "image_size = (96, 96, 3)\n",
        "\n",
        "\n",
        "def preprocess_img(images, size=(96, 96)):\n",
        "    return tf.image.resize(images, size)\n",
        "\n",
        "dataset = dataset.map(lambda images, labels: (preprocess_img(images), labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BsJAD-MeGzV"
      },
      "source": [
        "Split the dataset, you can use [different techniques](https://www.tensorflow.org/datasets/splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdQBZWhweGzW"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_size = int(0.75 * size)\n",
        "val_size = int(0.1 * size)\n",
        "\n",
        "train_ds = dataset.take(train_size)\n",
        "train_ds = train_ds.shuffle(1000).batch(batch_size).cache()\n",
        "remaining = dataset.skip(train_size)\n",
        "\n",
        "val_ds = remaining.take(val_size)\n",
        "test_ds = remaining.skip(val_size)\n",
        "\n",
        "val_ds = val_ds.shuffle(1000).batch(batch_size).cache()\n",
        "test_ds = test_ds.batch(batch_size).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnCcVzx5eGzW"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHniUhfpeGzW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RRRh5eS7AiO"
      },
      "source": [
        "# CNN model\n",
        "\n",
        "You can visit the tutorial [Introduction_to_CNN](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb)\n",
        "\n",
        "## CNN model in Keras\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://i.ibb.co/D8CmT6K/cnn.jpg\" alt=\"cnn\" border=\"0\">\n",
        "\n",
        "\n",
        "\n",
        "A Convolutional Neural Network (CNN) architecture has four main parts:\n",
        "\n",
        "- A **convolutional layer** that extracts features from a source image.\n",
        "\n",
        "- A **pooling layer** that reduces the image dimensionality without losing important features or patterns.\n",
        "\n",
        "- A **flattening layer** that transforms a n-dimensional tensor into a vector that can be fed into a fully connected neural network.\n",
        "\n",
        "- A **fully connected layer** also known as the dense layer.\n",
        "\n",
        "### Rescaling\n",
        "\n",
        "For converting the images to   \\[0,1\\] range.\n",
        "```python\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "next_layer = normalization_layer(prev_layer)\n",
        "```\n",
        "or simply\n",
        "```python\n",
        "reescaling = layers.Rescaling(1. / 255)(inputs)\n",
        "```\n",
        "\n",
        "### Convolutional layer\n",
        "\n",
        "In the convolutional layers (`Conv2D`) we will configure the following parameters:\n",
        "\n",
        "- **filters**: number of feature maps.\n",
        "- **kernel_size**: can be either an integer or a tuple of two integers. Specifies the height and width of the kernel.\n",
        "- **padding**: allows you to include padding in the input data. With 'valid' it is not applied, with 'same' it is configured so that the dimension at the output of the convolution is the same as at the input.\n",
        "- **activation**: activation function implemented. Recommended ReLU.\n",
        "\n",
        "[Link to documentation](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "\n",
        "```python\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
        "    activation=None, kernel_regularizer=None)\n",
        "\n",
        "```\n",
        "\n",
        "With Functional API:\n",
        "```python\n",
        "next_layer = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv_1')(prev_layer)\n",
        "```\n",
        "\n",
        "With Sequential:\n",
        "```python\n",
        "model.add(layers.Conv2D(filters=8,kernel_size=3, activation='relu', name='conv_1'))\n",
        "```\n",
        "\n",
        "### Pooling layer\n",
        "\n",
        "A pooling layer is a new layer added after the convolutional layer. Specifically, after a nonlinearity ( ReLU) you can choose between [average pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) or [max pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D). Usually max pooling is the best choice.\n",
        "\n",
        "\n",
        "With Functional API:\n",
        "```python\n",
        "conv_1 = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv_1')(prev_layer)\n",
        "\n",
        "pool_1 = layers.MaxPool2D(pool_size=(2, 2), name='pool_1')(conv_1)\n",
        "```\n",
        "\n",
        "With Sequential:\n",
        "```python\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2), name='pool_1'))\n",
        "```\n",
        "\n",
        "### Flattening\n",
        "\n",
        "Prepares a vector for the fully connected layers.\n",
        "\n",
        "With Functional API:\n",
        "\n",
        "```python\n",
        "next_layer = layers.Flatten(name='flatten')(prev_layer)\n",
        "```\n",
        "\n",
        "With Sequential:\n",
        "```python\n",
        "model.add(layers.Flatten(name='flatten'))\n",
        "```\n",
        "\n",
        "There is another alternative for flattening that is a type of pooling that is called global pooling. Global pooling down-samples the entire feature map to a single value.\n",
        "\n",
        "You can also choose between [GlobalAveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) and [GlobalMaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D).\n",
        "\n",
        "```python\n",
        "model.add(layers.GlobalMaxPool2D(name='GlobalMaxPooling2D'))\n",
        "```\n",
        "\n",
        "### Fully-connected layer\n",
        "\n",
        "Dense layer like a simple neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os9E78maeGzX"
      },
      "source": [
        "## Question 1: Create a model with two convolutional layers without pooling and without any regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdO4EeDWeGzX"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "reescaling = ...(inputs)\n",
        "\n",
        "# Conv Layer 1\n",
        "conv_1 = layers.Conv2D(...)(reescaling)\n",
        "\n",
        "# Conv Layer 2\n",
        "conv_2 = ...\n",
        "\n",
        "\n",
        "# Fully-connected\n",
        "# Flattening\n",
        "flat = ...(conv_2)\n",
        "...\n",
        "outputs = layers.Dense(...)(...)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shEsohu4eGzY"
      },
      "outputs": [],
      "source": [
        "model_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZQu8L9FeGzY"
      },
      "outputs": [],
      "source": [
        "epochs = 8\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    verbose=1)\n",
        "\n",
        "history = model_1.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GdcLg1ueGzY"
      },
      "outputs": [],
      "source": [
        "results = model_1.evaluate(test_ds, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddszTEMXeGzZ"
      },
      "outputs": [],
      "source": [
        "def show_errors(val_ds, model, class_names, n_images=10):\n",
        "    n_plots = 0\n",
        "    for images, labels in val_ds:\n",
        "        pred_prob = model.predict(images)\n",
        "        preds = (1.0 * (pred_prob >= 0.5)).astype(np.int32).flatten()\n",
        "        bad_pred_inds = np.where(preds != labels)[0]\n",
        "        for ind in list(bad_pred_inds):\n",
        "            n_plots += 1\n",
        "            real_class = class_names[labels[ind].numpy()]\n",
        "            pred_class = class_names[preds[ind]]\n",
        "            prob = pred_prob[ind][0]\n",
        "            plt.imshow(images[ind].numpy().astype(\"uint8\"))\n",
        "            plt.title('Predicted: {0}, prob: {1:.2f} \\n real: {2}'.format(\n",
        "                pred_class, prob, real_class))\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            if n_plots == n_images:\n",
        "                return\n",
        "    return\n",
        "\n",
        "\n",
        "show_errors(test_ds, model_1, class_names, n_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U9Rb52meGzZ"
      },
      "source": [
        "## Question 2: Introduce pooling to the previous model and obtain a better `test_accuracy`, Do not use any regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFB6mSPleGzZ"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "reescaling = ...(inputs)\n",
        "\n",
        "# Conv Layer 1 + pooling\n",
        "conv_1 = layers.Conv2D(...)(reescaling)\n",
        "\n",
        "# Conv Layer 2 + pooling\n",
        "conv_2 = ...\n",
        "\n",
        "\n",
        "# Fully-connected\n",
        "# Flattening\n",
        "flat = ...(conv_2)\n",
        "...\n",
        "outputs = layers.Dense(...)(...)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHmyPzpSeGza"
      },
      "outputs": [],
      "source": [
        "model_2.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "epochs = 8\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    verbose=1)\n",
        "\n",
        "history = model_2.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-cPzXS2eGzb"
      },
      "outputs": [],
      "source": [
        "results = model_2.evaluate(test_ds, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbWhsrsbeGzb"
      },
      "outputs": [],
      "source": [
        "show_errors(test_ds, model_2, class_names, n_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7s_yNBoeGzb"
      },
      "source": [
        "## Question 3: Introduce regularization (you can try data augmentation) and increase the number of layers to obtain a better `test_accuracy`. Try to obtain `Test Accuracy > 0.8`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7crf8IheGzb"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.25),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-RS8OYieGzc"
      },
      "outputs": [],
      "source": [
        "iinputs = tf.keras.Input(shape=..., name='input')\n",
        "reescaling = ...(inputs)\n",
        "\n",
        "# Conv Layer 1\n",
        "conv_1 = layers.Conv2D(...)(reescaling)\n",
        "\n",
        "# Conv Layer 2\n",
        "conv_2 = ...\n",
        "\n",
        "# Conv Layer ...\n",
        "\n",
        "\n",
        "# Fully-connected\n",
        "# Flattening\n",
        "flat = ...\n",
        "...\n",
        "outputs = layers.Dense(...)(...)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEUl7FLmeGzc"
      },
      "outputs": [],
      "source": [
        "model_3.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "epochs = 8\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    verbose=1)\n",
        "\n",
        "history = model_3.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVRhbjwceGzc"
      },
      "outputs": [],
      "source": [
        "results = model_3.evaluate(test_ds, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqVSj6xieGzd"
      },
      "outputs": [],
      "source": [
        "show_errors(test_ds, model_3, class_names, n_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fVV15W3eGzd"
      },
      "source": [
        "## Question 4: Try transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3IQloZXeGzd"
      },
      "outputs": [],
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(input_shape=image_size,\n",
        "                                                     include_top=False)\n",
        "pretrained_model.trainable = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCLm_hBGeGzd"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjxajIYceGzd"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=image_size, name='input')\n",
        "\n",
        "# pre-trained model\n",
        "... = preprocess_input(...)\n",
        "... = pretrained_model(..)\n",
        "\n",
        "# classifier\n",
        "flat = tf.keras.layers.Flatten()(...)\n",
        "outputs = ...\n",
        "\n",
        "model_tl = tf.keras.Model(inputs, outputs)\n",
        "model_tl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IKakf7heGze"
      },
      "outputs": [],
      "source": [
        "model_tl.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    verbose=1)\n",
        "\n",
        "history = model_tl.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj6g177WeGze"
      },
      "outputs": [],
      "source": [
        "results = model_tl.evaluate(test_ds, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJvi9oS9eGze"
      },
      "outputs": [],
      "source": [
        "show_errors(test_ds, model_tl, class_names, n_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61S2aJJYeGzf"
      },
      "source": [
        "# Generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2SOYs-9eGzf"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path, target_size=None):\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path,\n",
        "                target_size=target_size)\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = image.astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "def predict_plot(image_path, model, class_names, image_size):\n",
        "    image = read_image(image_path, image_size[:2])\n",
        "    prob = model.predict(np.expand_dims(image, 0))[0][0]\n",
        "    pred_class = class_names[(1.0 * (prob >= 0.5)).astype(np.int32)]\n",
        "    plt.imshow(image)\n",
        "    plt.title(\n",
        "        'Predicted: {0}, prob: {1:.2f}'\n",
        "        .format(pred_class, prob))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmKbvB5BeGzf"
      },
      "outputs": [],
      "source": [
        "url = 'https://assets.sainsburys-groceries.co.uk/gol/6754229/1/640x640.jpg'\n",
        "image_path = tf.keras.utils.get_file(\"dog_vs_cat_1.jpg\", url)\n",
        "print('model 1')\n",
        "predict_plot(image_path, model_1, class_names, image_size)\n",
        "print('model 2')\n",
        "predict_plot(image_path, model_2, class_names, image_size)\n",
        "print('model 3')\n",
        "predict_plot(image_path, model_3, class_names, image_size)\n",
        "print('model tl')\n",
        "predict_plot(image_path, model_tl, class_names, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4G4AWB0eGzf"
      },
      "outputs": [],
      "source": [
        "url = 'https://i.ytimg.com/vi/3dcli9i_pvA/hqdefault.jpg'\n",
        "image_path = tf.keras.utils.get_file(\"dog_vs_cat_2.jpg\", url)\n",
        "print('model 1')\n",
        "predict_plot(image_path, model_1, class_names, image_size)\n",
        "print('model 2')\n",
        "predict_plot(image_path, model_2, class_names, image_size)\n",
        "print('model 3')\n",
        "predict_plot(image_path, model_3, class_names, image_size)\n",
        "print('model tl')\n",
        "predict_plot(image_path, model_tl, class_names, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fijCROyseGzg"
      },
      "outputs": [],
      "source": [
        "url = 'https://thumbs.dreamstime.com/b/halloween-ghost-portrait-funny-dog-black-background-adorable-pup-muzle-153863580.jpg'\n",
        "image_path = tf.keras.utils.get_file(\"dog_vs_cat_3.jpg\", url)\n",
        "print('model 1')\n",
        "predict_plot(image_path, model_1, class_names, image_size)\n",
        "print('model 2')\n",
        "predict_plot(image_path, model_2, class_names, image_size)\n",
        "print('model 3')\n",
        "predict_plot(image_path, model_3, class_names, image_size)\n",
        "print('model tl')\n",
        "predict_plot(image_path, model_tl, class_names, image_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}