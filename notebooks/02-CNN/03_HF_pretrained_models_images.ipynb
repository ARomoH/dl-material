{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hFqIFluX5AgomZYdb5PVn4kMXJiZ0t3d?usp=sharing)"
      ],
      "metadata": {
        "id": "yfFpfulj8JdJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh6QOr-qO4Ym"
      },
      "source": [
        "# Pretrained models in HuggingFace - Overview Notebook\n",
        "\n",
        "This notebook is a self-contained way to start using transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Iv1CJZPekG"
      },
      "source": [
        "**Learning goals:** The goal of this tutorial is to learn How To\n",
        "\n",
        "1. Use pre-trained pipelines\n",
        "2. Get embeddings\n",
        "3. Build a multimodal models\n",
        "\n",
        "**Steps to Do:** How to best use this notebook\n",
        "\n",
        "1. Make a copy of this notebook, so you can keep your changes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb65KY8VcSV8"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet transformers datasets sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpvE1ionWmLy"
      },
      "source": [
        "## Pre-Trained Models with Pipelines -> ✨ Easy Mode ✨\n",
        "\n",
        "The [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) supports many 20+ common tasks out-of-the-box:\n",
        "\n",
        "**Image**:\n",
        "* Image classification: classify an image.\n",
        "* Image segmentation: classify every pixel in an image.\n",
        "* Object detection: detect objects within an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3iwLYgdDd4-"
      },
      "source": [
        "### Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJIC5gtzIFT3"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uImYTfZC5Kr"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "vision_classifier = pipeline(task=\"image-classification\")\n",
        "imagepic=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        "result = vision_classifier(\n",
        "    images=imagepic\n",
        ")\n",
        "print(\"\\n\".join([f\"Class {d['label']} with score {round(d['score'], 4)}\" for d in result]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load specific endpoint"
      ],
      "metadata": {
        "id": "TEU800aEPKsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vision_classifier = pipeline(task=\"image-classification\", model='microsoft/resnet-50')\n",
        "imagepic=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        "result = vision_classifier(\n",
        "    images=imagepic\n",
        ")\n",
        "print(\"\\n\".join([f\"Class {d['label']} with score {round(d['score'], 4)}\" for d in result]))"
      ],
      "metadata": {
        "id": "R-2KIYfoPJtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load as extractor + model\n",
        "\n",
        "We have to do exta steps to perform inference"
      ],
      "metadata": {
        "id": "AUS1q-8nP7BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# get image in PIL format\n",
        "response = requests.get(imagepic)\n",
        "img = Image.open(BytesIO(response.content))"
      ],
      "metadata": {
        "id": "ahA0OaBnQpU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
        "import torch\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "inputs = processor(img, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# Apply softmax to the logits to get probabilities\n",
        "probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# Get the top 5 predicted labels and their corresponding probabilities\n",
        "top5_probabilities, top5_indices = torch.topk(probabilities, 5, dim=-1)\n",
        "\n",
        "# Get the class labels corresponding to the top 5 indices\n",
        "class_labels = [model.config.id2label[index.item()] for index in top5_indices[0]]\n",
        "\n",
        "# Print the top 5 predicted classes and their probabilities\n",
        "for i, (label, probability) in enumerate(zip(class_labels, top5_probabilities[0])):\n",
        "    print(f\"Top {i + 1}: Class '{label}' with Probability: {probability.item()}\")"
      ],
      "metadata": {
        "id": "beoWWopWP5r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image embeddings using [Distilled data-efficient Image Transformer (DeiT)](https://huggingface.co/facebook/deit-base-distilled-patch16-224)"
      ],
      "metadata": {
        "id": "ftQlssWbaA50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4puw90EWSPie"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "im = Image.open(requests.get(imagepic, stream=True).raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
        "embeddings = feature_extractor(images=im, return_tensors=\"pt\")\n",
        "embeddings"
      ],
      "metadata": {
        "id": "oJRdq6OYaF-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}