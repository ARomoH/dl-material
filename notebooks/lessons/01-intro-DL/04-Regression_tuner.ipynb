{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f310246",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "tf.keras.utils.set_random_seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e3013",
   "metadata": {},
   "source": [
    "# Abalone Dataset\n",
    "\n",
    "Abalones are marine snails that can be found along coasts of almost every continent. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/AbaloneInside.jpg/440px-AbaloneInside.jpg\" alt=\"abalone\" border=\"0\" width=\"400\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we are going to Predict the age of abalone from physical measurements. [Link to documentation](https://archive.ics.uci.edu/ml/datasets/abalone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c6c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c554e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('Age')\n",
    "X_train = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "y_test = df_test.pop('Age')\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de841977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bf8de",
   "metadata": {},
   "source": [
    "## Regression Losses\n",
    "\n",
    "- **Mean Squared Error (MSE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MSE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mse') or model.compile(loss=tf.keras.losses.MSE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i}\\right)^2}{n}$$\n",
    "\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MAE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mae') or model.compile(loss=tf.keras.losses.MAE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i - \\hat{y_i}\\right|}{n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313693e1",
   "metadata": {},
   "source": [
    "## Question 1: Create a sequential net with at least 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f142132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(..., input_shape=(...,), activation=...))\n",
    "...\n",
    "# output layer\n",
    "model.add(layers.Dense(..., activation=...))\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb1a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=...,\n",
    "    metrics=[...]\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c909754",
   "metadata": {},
   "source": [
    "## Question 2: Normalize the inputs and train the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = ...\n",
    "X_test_norm = ...\n",
    "print('X_train mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
    "print('X_test mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "...\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=['mae']\n",
    ")\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6040ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de862aa9",
   "metadata": {},
   "source": [
    "##\u00a0Optimizers:\n",
    "\n",
    "- [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD): Gradient descent with momentum\n",
    "```python\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
    ")\n",
    "```\n",
    "If momentum is 0:\n",
    "```python\n",
    "w = w - learning_rate * gradient\n",
    "```\n",
    "If we have momentum:\n",
    " \n",
    " ```python\n",
    "velocity = momentum * velocity - learning_rate * g\n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "\n",
    "- [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop): Root Mean Square Propagation\n",
    "```python\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "```\n",
    "- [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam): Adaptive Moment Estimation,  is an update to the RMSProp algorithm\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d744232",
   "metadata": {},
   "source": [
    "## Question 3: Train the same model with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "...\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=...,\n",
    "    loss=...,\n",
    "    metrics=[...]\n",
    ")\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36eaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377a7ff",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "\n",
    "The [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) is a library for hyper-parameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b048",
   "metadata": {},
   "source": [
    "Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
    "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
    "\n",
    "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
    "\n",
    "```python\n",
    "def build_model(hp):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "```\n",
    "\n",
    "- `hp.Int` to sample an integer from a certain range:\n",
    "```python\n",
    "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
    "```\n",
    "- `hp.Float` to sample a float number from a certain range:\n",
    "```python\n",
    "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
    "```\n",
    "- `hp.Choice` to select values in a list:\n",
    "```python\n",
    "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "```\n",
    "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    #\u00a0Sample different number of layers with hp.Int\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        #\u00a0Sample different number of layers with hp.Int\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=128,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    #\u00a0Sample different activation functions with hp.Choice \n",
    "    model.add(layers.Dense(1, activation=hp.Choice('output_activation', ['relu', 'linear'])))\n",
    "    \n",
    "    #\u00a0Sample different activation functions with hp.Choice \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mse',\n",
    "        metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71047eeb",
   "metadata": {},
   "source": [
    "The Keras Tuner has four [tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) available  `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8261f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=35,\n",
    "                     factor=2,\n",
    "                     hyperband_iterations=1,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=100,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15, batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9ffad",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf5a27",
   "metadata": {},
   "source": [
    "## Question 4: Try to search with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=40,\n",
    "                     factor=2,\n",
    "                     hyperband_iterations=2,\n",
    "                     directory='my_dir_2',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15,\n",
    "             batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")\n",
    "    #print(f\"Dropout rate of hidden layer {i+1}: {best_hps.get('dp_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f46fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}