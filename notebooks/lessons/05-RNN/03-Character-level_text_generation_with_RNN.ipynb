{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/RNN/Character-level_text_generation_with_RNN.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Character-level_text_generation_with_RNN.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyQAB371QNRK"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAKzQV3UQNRK"
   },
   "source": [
    "### Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9U1NwwiGao5"
   },
   "outputs": [],
   "source": [
    "##\u00a0download the dataser\n",
    "# quijote : https://www.gutenberg.org/files/2000/2000-0.txt\n",
    "'''path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")'''\n",
    "path = keras.utils.get_file(\n",
    "    \"quijote_spanish.txt\", origin=\"https://www.gutenberg.org/files/2000/2000-0.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEZ6FnzjGao5",
    "outputId": "448d833f-ec3d-4037-c2f8-6566bfbfdd49"
   },
   "outputs": [],
   "source": [
    "text = open(path).read().lower()\n",
    "## don quijote\n",
    "text = text[39972:]\n",
    "print('corpus length:', len(text))\n",
    "print('corpus words:', len(text.split(' ')))\n",
    "# text = text[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-GgVsFIGao6",
    "outputId": "74d520ca-a658-410e-8180-5c221b0ef072"
   },
   "outputs": [],
   "source": [
    "# print the firsts characters\n",
    "#print(text[:200])\n",
    "# remove newlines chars \n",
    "text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip()  \n",
    "print()\n",
    "print('processed texts:')\n",
    "print()\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OORRPlvDGao6"
   },
   "source": [
    "### Text simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcX2QPi-Gao6",
    "outputId": "64eb80c2-16ed-4003-f88a-928952a77b4e"
   },
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "print(\"Total chars:\", len(chars))\n",
    "\n",
    "char_indices = {c:i for i, c in enumerate(chars)}\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9AgEunWGao7",
    "outputId": "6162ef23-99ca-453c-9d22-7803c6f1a30a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "char_counts = Counter(text)\n",
    "char_counts_sort = [\n",
    "    (ch, count)\n",
    "    for ch, count in sorted(char_counts.items(), key=lambda x: -x[1])\n",
    "]\n",
    "print('Most frequent characters:', char_counts_sort[:10])\n",
    "print('less frequent characters:', char_counts_sort[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2ojq9NrGao7",
    "outputId": "b35f705d-4bde-478c-aa35-6296caf5d885"
   },
   "outputs": [],
   "source": [
    "max_chars = 35\n",
    "##\u00a0We replace the less used characters with unknown_char\n",
    "unknown_char = '\u00f2'\n",
    "\n",
    "chars = {ch for ch,count in char_counts_sort[:max_chars-1]}\n",
    "print(unknown_char in chars)\n",
    "char_indices = {c:i+1 for i, c in enumerate(chars)}\n",
    "char_indices[unknown_char] = 0\n",
    "indices_char = {i:c for c,i in char_indices.items()}\n",
    "chars.add(unknown_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXDImInIGao8"
   },
   "outputs": [],
   "source": [
    "# reduce the size\n",
    "text = text[:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isL_xU24Gao8"
   },
   "source": [
    "Next we generate the input and output arrays:\n",
    "\n",
    "The input will consist on sentences of a fixed (maxlen) lenght, while the outputs will be the next characters in the text.\n",
    "\n",
    "So, if the text is \"Welcome to deep learning course\" with maxlen = 5, we will have:\n",
    "\n",
    "Input = [ w, e, l, c, o, e, l, c, o, m, l, c, o, m, e, ... ] Output = [ m, e, , ... ]\n",
    "In order to avoid overfitting (and improve performances) we can add a step to the structure so that with step = 3, for example:\n",
    "\n",
    "Input = [ w, e, l, c, o, c, o, m, e, , m, e, , t, o, ... ] Output = [ m, t, , ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZHBgup2QNRL",
    "outputId": "b421d805-ea95-416c-d296-383e4ba931a6"
   },
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3kMTe-RGao8",
    "outputId": "0f90ef0e-966d-4a65-93ff-9d6db187ec31"
   },
   "outputs": [],
   "source": [
    "sentences[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moytr1PBGao9",
    "outputId": "705c363c-0853-439d-8d24-ff0d42776002"
   },
   "outputs": [],
   "source": [
    "next_chars[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3V4GaHYcGao9"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros(len(sentences), dtype=np.int32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices.get(char, 0)] = 1\n",
    "    y[i] = char_indices.get(next_chars[i], 0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXRHOB50QNRL"
   },
   "source": [
    "## Build the model: a single LSTM layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUd7xS1PQNRL"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xgj88iRAGao9"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.2):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vkJoOcL9Gao-",
    "outputId": "b5c91c74-a2ef-4b7c-8ad9-7ac80c7bb2ee"
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 256\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/10)):\n",
    "    if epoch_ind < 4:\n",
    "        epoch += 1\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 10\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=10)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(150):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnJTL_VJZaYi"
   },
   "source": [
    "###\u00a0Sabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RRefCIyGapC"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6inpv1mGapC",
    "outputId": "f3ec0d0d-7347-4a8b-e29c-9c6e4f621cfa"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.letras.com/joaquin-sabina/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIG1O9VIGapC"
   },
   "outputs": [],
   "source": [
    "def check_is_paragraph(row):\n",
    "    return all([\n",
    "        b.name == 'br' or type(b) == bs4.element.NavigableString\n",
    "        for b in row.contents\n",
    "    ])\n",
    "\n",
    "def get_paragraph_text_0(row):\n",
    "    sentences = []\n",
    "    for b in row.contents:\n",
    "        phrase = ''\n",
    "        if type(b) == bs4.element.NavigableString:\n",
    "            phrase = b.strip()\n",
    "        elif b.name == 'br':\n",
    "            phrase = b.get_text().strip()\n",
    "        if phrase:\n",
    "            sentences.append(phrase)\n",
    "    return sentences\n",
    "\n",
    "def get_paragraph_text(row):\n",
    "    sentences = []\n",
    "    for b1 in row.contents:\n",
    "        phrase = ''\n",
    "        if type(b1) == bs4.element.NavigableString:\n",
    "            phrase = b1.strip()\n",
    "        elif len(b1.contents) > 1 and check_is_paragraph(b1):\n",
    "            phrase = ' '.join(get_paragraph_text_0(b1))\n",
    "        elif b1.name == 'br':\n",
    "            phrase = b1.get_text().strip()\n",
    "        if phrase:\n",
    "            sentences.append(phrase)\n",
    "    return sentences\n",
    "\n",
    "def get_song(song_soup):\n",
    "    first = False\n",
    "    song = []\n",
    "    for i, row in enumerate(song_soup.findAll('p')):\n",
    "        is_paragraph = check_is_paragraph(row)\n",
    "        if not first and is_paragraph:\n",
    "            first = True\n",
    "        if first and not is_paragraph:\n",
    "            break\n",
    "        if is_paragraph:\n",
    "            paragraph = get_paragraph_text(row)\n",
    "            song += paragraph\n",
    "    return '\\n'.join(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0rGU5_cGapC",
    "outputId": "3a21cd4e-9a07-4157-df74-5e00650774f3"
   },
   "outputs": [],
   "source": [
    "complete_songs = []\n",
    "all_rows = soup.findAll('a', {'class':\"song-name\"}, href=True)\n",
    "for row in all_rows:\n",
    "    song_url = 'https://www.letras.com' + row['href']\n",
    "    song_page = requests.get(song_url)\n",
    "    song_soup = BeautifulSoup(song_page.text, 'html.parser')\n",
    "    song = get_song(song_soup)\n",
    "    print('######################')\n",
    "    print(song_url)\n",
    "    print(song)\n",
    "    complete_songs.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TQ1Hh99GapD"
   },
   "outputs": [],
   "source": [
    "text_sabina = ' '.join(complete_songs).replace('\\n', ' ').replace('  ', ' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWUtcVk5GapD",
    "outputId": "92960220-cc2b-4125-9b33-131644f41178"
   },
   "outputs": [],
   "source": [
    "len(text_sabina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVW1ssYYaJLi"
   },
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "def get_sentences(text, maxlen, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print(\"Number of sequences:\", len(sentences))\n",
    "    return sentences, next_chars\n",
    "\n",
    "def preprocess_text(sentences, chars, char_indices):\n",
    "    x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros(len(sentences), dtype=np.int32)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices.get(char, 0)] = 1\n",
    "        y[i] = char_indices.get(next_chars[i], 0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpuALxMDayA8",
    "outputId": "0ae87ce6-c2ac-49dc-823a-9701639482f1"
   },
   "outputs": [],
   "source": [
    "sentences, next_chars = get_sentences(text_sabina, maxlen, step)\n",
    "x, y = preprocess_text(sentences, chars, char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5hREkqXaJLl",
    "outputId": "e542c962-e97e-49a3-82f6-564e8e6a6a18"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnWoy7_sbZ-j"
   },
   "source": [
    "### Continues with the songs of Sabina with the model trained with Don Quixote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbUrQy91aJLm"
   },
   "outputs": [],
   "source": [
    "def continue_sentence(model, sentence, sentence_length, char_indices, maxlen, chars, diversity=0.2):\n",
    "    generated = \"\"\n",
    "    for i in range(sentence_length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "        preds = model(x_pred).numpy()[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        sentence = sentence[1:] + next_char\n",
    "        generated += next_char\n",
    "    print(\"...Generated: \", generated)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pMC5z6EuGapD",
    "outputId": "735dfaf8-d662-4854-d4bb-1e2dd92485a2"
   },
   "outputs": [],
   "source": [
    "ind = np.random.randint(len(sentences))\n",
    "sentence = sentences[ind]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "b2srfeBAGapD",
    "outputId": "f11f60f7-7e08-45ca-cc65-eb9af477dabe"
   },
   "outputs": [],
   "source": [
    "generated = continue_sentence(model, sentence, 50, char_indices, maxlen, chars, diversity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXI3o_SVe3xY"
   },
   "outputs": [],
   "source": [
    "model_sabina= keras.models.clone_model(model)\n",
    "model_sabina.set_weights(model.get_weights())\n",
    "model_sabina.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gJb8cfYGapE",
    "outputId": "a086d366-804b-4028-9be9-4fd873862e5a"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/5)):\n",
    "    if epoch_ind <= 2:\n",
    "        model_sabina.fit(x, y, batch_size=1024 * 8, epochs=1)\n",
    "    elif epoch_ind < 10:\n",
    "        epoch += 1\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 5\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=5)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_sabina) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text_sabina[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(250):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model_sabina(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: Create a model with regularization and compare the results only with the corpus of Sabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sabina = keras.Sequential()\n",
    "model_sabina.add(keras.Input(shape=(maxlen, len(chars))))\n",
    "model_sabina.add(...)\n",
    "model_sabina.add(layers.Dense(len(chars), activation=...))\n",
    "model_sabina.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 128\n",
    "\n",
    "epoch = 0\n",
    "for epoch_ind in range(int(epochs/5)):\n",
    "    if epoch_ind < 5:\n",
    "        epoch += 1\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    else:\n",
    "        epoch += 5\n",
    "        model_sabina.fit(x, y, batch_size=batch_size, epochs=5)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_sabina) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "        generated = \"\"\n",
    "        sentence = text_sabina[start_index: start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(250):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices.get(char, 0)] = 1.0\n",
    "            preds = model_sabina(x_pred).numpy()[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\u00a0References\n",
    "[https://keras.io/examples/generative/lstm_character_level_text_generation/](https://keras.io/examples/generative/lstm_character_level_text_generation/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}