{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1DbnHZivcrvqTdd0H6AmdFiFLfLAu_7ft?usp=sharing)"
      ],
      "metadata": {
        "id": "NVBHIptIFxZ3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh6QOr-qO4Ym"
      },
      "source": [
        "# Pretrained models in HuggingFace - Overview Notebook\n",
        "\n",
        "This notebook is a self-contained way to start using transformers.\n",
        "\n",
        "- https://github.com/nlp-with-transformers/notebooks/blob/main/01_introduction.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Iv1CJZPekG"
      },
      "source": [
        "**Learning goals:** The goal of this tutorial is to learn How To\n",
        "\n",
        "1. Use pre-trained pipelines\n",
        "2. Get embeddings\n",
        "3. Build a multimodal models\n",
        "\n",
        "**Steps to Do:** How to best use this notebook\n",
        "\n",
        "1. Make a copy of this notebook, so you can keep your changes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb65KY8VcSV8"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet transformers datasets sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpvE1ionWmLy"
      },
      "source": [
        "## Pre-Trained Models with Pipelines -> ✨ Easy Mode ✨\n",
        "\n",
        "The [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) supports many 20+ common tasks out-of-the-box:\n",
        "\n",
        "**Text**:\n",
        "* Sentiment analysis: classify the polarity of a given text.\n",
        "* Text generation (in English): generate text from a given input.\n",
        "* Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.).\n",
        "* Question answering: extract the answer from the context, given some context and a question.\n",
        "\n",
        "\n",
        "**Audio**:\n",
        "* Audio classification: assign a label to a given segment of audio.\n",
        "* Automatic speech recognition (ASR): transcribe audio data into text.\n",
        "\n",
        "**MultiModal**:\n",
        "* Visual Question Answering: answers open-ended questions about images\n",
        "* Image To Text: predicts a caption for a given image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAdyiTBfn89u"
      },
      "source": [
        "### Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BdG8xniVmka"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "sent_classifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKkkyOlfcing"
      },
      "outputs": [],
      "source": [
        "sent_classifier(\"I am sad about today\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using tokenizer and transformers"
      ],
      "metadata": {
        "id": "Lhi2S753bhby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "3YsJtCYwbeLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"La mesa buenisima relacion precio muy recomendable.\"\n",
        "\n",
        "inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class = logits.argmax().item()\n",
        "\n",
        "print(model.config.id2label[predicted_class])"
      ],
      "metadata": {
        "id": "bjnTys5Zbu5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ksx_p5Vn_fs"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEhd0L8J6QRO"
      },
      "source": [
        "If you want to see what other tasks are available, check out all the [pipeline tasks](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#the-task-specific-pipelines) in the docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_KuISyQtcPI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline(\"text-generation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68DDB1ittVvv"
      },
      "outputs": [],
      "source": [
        "generator(\"Once upon a time,\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXE5JFkHlmLC"
      },
      "outputs": [],
      "source": [
        "generator(\"In this course, we will teach you how to\", max_length=200, truncation=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Name entity recognition"
      ],
      "metadata": {
        "id": "j3u-QeLBc8Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ],
      "metadata": {
        "id": "jtIK4Cmlc8Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "outputs = ner_tagger(sample_text)\n",
        "pd.DataFrame(outputs)"
      ],
      "metadata": {
        "id": "LSDjkqwEc62A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization"
      ],
      "metadata": {
        "id": "AKs8biiZdPN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ],
      "metadata": {
        "id": "CPOOMd13dTOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "outputs = summarizer(sample_text, max_length=45, clean_up_tokenization_spaces=True)\n",
        "print(outputs[0]['summary_text'])"
      ],
      "metadata": {
        "id": "A5R1BEP-dF4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A2paz6EOZr9"
      },
      "source": [
        "### MultiModal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# get image in PIL format\n",
        "imagepic = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        "Image(imagepic)"
      ],
      "metadata": {
        "id": "TuB_uOMHcdn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0XkhAkInazD"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForVisualQuestionAnswering\n",
        "\n",
        "vqa_pipeline = pipeline(\"visual-question-answering\")\n",
        "vqa = vqa_pipeline(image=imagepic,\n",
        "                   question = \"What is the weather like\")\n",
        "                  # question = \"What color are the bushes\")\n",
        "vqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8eZ-4I36a1P"
      },
      "source": [
        "### Text Embeddings using Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M880_gzn6rxI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "checkpoint = \"facebook/bart-base\"\n",
        "pipeline = pipeline(\"feature-extraction\",framework=\"pt\",model=checkpoint)\n",
        "text = \"Transformers is an awesome library!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEvZNYkDyrbb"
      },
      "outputs": [],
      "source": [
        "embeddings = pipeline(text,return_tensors = \"pt\")[0].numpy().mean(axis=0)\n",
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS_UIFY4tdcJ"
      },
      "source": [
        "### Text Embeddings using Sentence Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYQPJ-O9vut"
      },
      "source": [
        "There are many embedding models, the [all-mpnet-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) model is generally recommended as a good all around model. A more lightweight embedding model is the [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). For a comprehensive analysis of embedding models, take a look at the [Massive Text Embedding Benchmark leaderboard](https://huggingface.co/spaces/mteb/leaderboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwSELkyarQgO"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "modelst = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "sentence = ['It is a rainy and snowy day in Chicago']\n",
        "embedding = modelst.encode(sentence)\n",
        "embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4puw90EWSPie"
      },
      "outputs": [],
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKeKsHkbcWax"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}