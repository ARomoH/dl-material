{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSGKW5-FgpzF"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LaeF0T-i7rawqlOJbuLiv-BLSuUu5Jaj?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchview"
      ],
      "metadata": {
        "id": "_lkzTX1rMmdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VpInRBCgpzH"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQRo1pMagpzJ"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    h = 0.05\n",
        "\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min.to(\"cpu\").numpy(), x_max.to(\"cpu\").numpy(), h),\n",
        "                         np.arange(y_min.to(\"cpu\").numpy(), y_max.to(\"cpu\").numpy(), h))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]  # Flatten the grid to pass into the model\n",
        "\n",
        "    # Convert grid to a torch tensor and make predictions\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
        "        preds = model(grid_tensor).squeeze()\n",
        "        preds = (preds >= 0.5).float().to(\"cpu\").numpy()\n",
        "\n",
        "    Z = preds.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
        "    plt.scatter(X.to(\"cpu\").numpy()[:, 0], X.to(\"cpu\").numpy()[:, 1],\n",
        "                c=y.to(\"cpu\").numpy().ravel(), cmap=plt.cm.Spectral, edgecolors=\"k\")\n",
        "    plt.xlabel(\"x1\")\n",
        "    plt.ylabel(\"x2\")\n",
        "    plt.title(\"Decision Boundary\")\n",
        "\n",
        "def load_planar_dataset(m, sigma=0.2):\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 4 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        ix = range(N*j,N*(j+1))\n",
        "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*sigma # theta\n",
        "        r = a*np.sin(4*t) + np.random.randn(N)*sigma # radius\n",
        "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "        Y[ix] = j\n",
        "\n",
        "    ## premuting ouput\n",
        "    p = np.random.permutation(m)\n",
        "    X = X[p,:]\n",
        "    Y = Y[p,:]\n",
        "\n",
        "    return X, Y.ravel()\n",
        "\n",
        "def draw_neural_net(left, right, bottom, top, layer_sizes):\n",
        "    '''\n",
        "    From https://gist.github.com/craffel/2d727968c3aaebd10359#file-draw_neural_net-py\n",
        "    Draw a neural network cartoon using matplotilb.\n",
        "\n",
        "    :usage:\n",
        "        >>> fig = plt.figure(figsize=(12, 12))\n",
        "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
        "\n",
        "    :parameters:\n",
        "        - ax : matplotlib.axes.AxesSubplot\n",
        "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
        "        - left : float\n",
        "            The center of the leftmost node(s) will be placed here\n",
        "        - right : float\n",
        "            The center of the rightmost node(s) will be placed here\n",
        "        - bottom : float\n",
        "            The center of the bottommost node(s) will be placed here\n",
        "        - top : float\n",
        "            The center of the topmost node(s) will be placed here\n",
        "        - layer_sizes : list of int\n",
        "            List of layer sizes, including input and output dimensionality\n",
        "    '''\n",
        "    fig = plt.figure(figsize=(3, 3))\n",
        "    ax = fig.gca()\n",
        "    ax.axis('off')\n",
        "\n",
        "    n_layers = len(layer_sizes)\n",
        "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
        "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
        "    # Nodes\n",
        "    for n, layer_size in enumerate(layer_sizes):\n",
        "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
        "        for m in range(layer_size):\n",
        "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
        "                                color='w', ec='k', zorder=4)\n",
        "            ax.add_artist(circle)\n",
        "    # Edges\n",
        "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
        "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
        "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
        "        for m in range(layer_size_a):\n",
        "            for o in range(layer_size_b):\n",
        "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
        "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
        "                ax.add_artist(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNEdfkm3gpzK"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We have a binary classification dataset. The target `y` has two possible values, {0,1} and the input vector `x` has two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhRpWUrygpzK"
      },
      "outputs": [],
      "source": [
        "N = 5000\n",
        "X_np, y_np = load_planar_dataset(N, 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z4aGBp8gpzL"
      },
      "source": [
        "Visualize the dataset using matplotlib. The data looks like a \"flower\" with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr2SnIMBgpzL"
      },
      "outputs": [],
      "source": [
        "# Visualize the data:\n",
        "plt.scatter(X_np[:,0], X_np[:,1], c=y_np.ravel(), s=40, cmap=plt.cm.Spectral);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMyoGCCJgpzM"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train_np, X_test_np, y_train_np, y_test_np) = train_test_split(\n",
        "    X_np,\n",
        "    y_np,\n",
        "    test_size=0.2,\n",
        "    random_state=14\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xZIwTEJgpzM"
      },
      "outputs": [],
      "source": [
        "print('X shape:{0}, y shape:{1}'.format(X_np.shape, y_np.shape))\n",
        "print('X_train shape:{0}, y_train shape:{1}'.format(X_train_np.shape,\n",
        "                                                    y_train_np.shape))\n",
        "print('X_test shape:{0}, y_test shape:{1}'.format(X_test_np.shape, y_test_np.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQwkPhIwgpzM"
      },
      "outputs": [],
      "source": [
        "## X first example\n",
        "X_np[0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfsHE9JzgpzN"
      },
      "outputs": [],
      "source": [
        "## Y firsts examples\n",
        "y_np[:8]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy array to tensors\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "X_train = torch.from_numpy(X_train_np).type(torch.float).to(device)\n",
        "X_test = torch.from_numpy(X_test_np).type(torch.float).to(device)\n",
        "y_train = torch.from_numpy(y_train_np).type(torch.float).to(device)\n",
        "y_test = torch.from_numpy(y_test_np).type(torch.float).to(device)\n",
        "\n",
        "print(f\"y_test type: {type(y_test)}\\nE.g.: {y_test[:8]}\")"
      ],
      "metadata": {
        "id": "Y8ZHu14iQCUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcgUzyVqgpzN"
      },
      "source": [
        "## First NN in torch\n",
        "\n",
        "\n",
        "\n",
        "*   [**torch.nn**](https://pytorch.org/docs/stable/nn.html): basic building blocks to create NN architecture.\n",
        "*   [**torch.nn.Parameter**](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter): tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters\n",
        "*   [**torch.nn.Module**](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module): base class for all neural network modules\n",
        "*   [**torch.optim**](https://pytorch.org/docs/stable/optim.html): package implementing various optimization algorithms.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Logistic regression\n",
        "\n",
        "Fully connected layers are defined using the [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "```\n",
        "\n",
        "- **nn.module**: Contains all the building blocks of the neuronal network.\n",
        "- **init**: initalise model parameters to be used several computations (these could be different layers from **torch.nn**, single paramters, etc.)\n",
        "- **forward**: any nn.module need to overwrite the forward function to indicate model proper way to execute layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aWtUVN7gpzN"
      },
      "outputs": [],
      "source": [
        "draw_neural_net(.1, .9, .1, .9, [2, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "model = LogisticRegression(input_dim=2)"
      ],
      "metadata": {
        "id": "0Vx4vHNnKdM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list parameters\n",
        "model_params = list(model.parameters())\n",
        "print(f\"Trainable parameters n={len(model_params)}\\n{model_params}\")\n",
        "\n",
        "# named parameters\n",
        "print(f\"\\nNamed parameters: {model.state_dict()}\")"
      ],
      "metadata": {
        "id": "OOrht0cYMLt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# models also have a device\n",
        "next(model.parameters()).device"
      ],
      "metadata": {
        "id": "DH1eCb5tQSdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# architecture\n",
        "print(model)"
      ],
      "metadata": {
        "id": "4N-MRCDPMd9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "id": "6nrhgdyXNS85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjQHremngpzO"
      },
      "source": [
        "#### Compile\n",
        "Now we need to specify the loss function, the metrics and the optimizer. It is done using compile function in Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIPBa3OggpzO"
      },
      "outputs": [],
      "source": [
        "# create the loss function\n",
        "loss_fn = nn.BCELoss() # Binary cross entropy\n",
        "\n",
        "# create the optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quon44-egpzO"
      },
      "source": [
        "#### Training model\n",
        "\n",
        "Torch required to iterate over epochs and define each step"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(y_hat, y):\n",
        "    y_hat_class = (y_hat > 0.5).float()\n",
        "    return (y == y_hat_class).float().mean() * 100"
      ],
      "metadata": {
        "id": "6yjZY1iMQkua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1upuP_igpzO"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "\n",
        "    # put model in training mode (this is the default state of a model)\n",
        "    model.train()\n",
        "\n",
        "    # 1. forward pass on train data\n",
        "    y_pred = model(X_train).squeeze()\n",
        "\n",
        "    # 2. calculate the loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      # 1. forward pass on test data\n",
        "      test_pred = model(X_test).squeeze()\n",
        "\n",
        "      # 2. Calculate metrics for test and train\n",
        "      test_accuracy = get_accuracy(test_pred, y_test)\n",
        "      train_accuracy = get_accuracy(y_pred, y_train)\n",
        "\n",
        "      # 3. caculate loss on test data\n",
        "      test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "      # Display metrics every epoch\n",
        "      if epoch % 1 == 0:\n",
        "            print(f\"Epoch: {epoch} | Train Loss={loss:.2f} & Accuracy={train_accuracy:.2f} \" \\\n",
        "                  f\"| Test Loss={test_loss:.2f} & Accuracy={test_accuracy:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfUrCkyagpzO"
      },
      "source": [
        "#### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmLEjY-ugpzO"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9neTs1ZVabt"
      },
      "outputs": [],
      "source": [
        "# clasification metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_preds_np = y_preds.to(\"cpu\").numpy()\n",
        "y_pred_class = (y_preds_np > 0.5).astype('int32')\n",
        "\n",
        "print(confusion_matrix(y_test_np, y_pred_class))\n",
        "print(classification_report(y_test_np, y_pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"Binary Classification Decision Boundary with PyTorch Model\")"
      ],
      "metadata": {
        "id": "Bcay5FkOY-I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsD7-3idgpzP"
      },
      "source": [
        "### One hidden layer NN\n",
        "\n",
        "https://playground.tensorflow.org/\n",
        "\n",
        "- One **input with 2 features (input_shape)**\n",
        "- **One hidden dense layer**,  with **3 neurons** and implemented with  **sigmoid activating function**\n",
        "- **One Output** (sigmoid output activation function)\n",
        "\n",
        "We can create layers incrementally with the method `add()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WHjmrlHgpzP"
      },
      "outputs": [],
      "source": [
        "draw_neural_net(.1, .9, .1, .9, [2, 3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHiddenNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=input_dim, out_features=3)\n",
        "        self.head_layer = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer(x)\n",
        "        out = self.head_layer(out)\n",
        "        # remove sigmoid here (we'll see why)\n",
        "        # out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = OneHiddenNN(input_dim=2)\n",
        "model"
      ],
      "metadata": {
        "id": "bllWnmOaZ5Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sS01735gpzP"
      },
      "outputs": [],
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define loss and get optimizer\n",
        "# We use a new loss (more numerically stable)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "metadata": {
        "id": "qmPCxSWai2Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The missing part: batch size.**\n",
        "\n",
        "So far we have updated the weights of our models using all the training data. As we saw in the theory, with more complex networks and more data volume this is not optimal. Therefore we must introduce gradient descent via mini batch.\n",
        "\n",
        "- [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset): Dataset wrapping tensors. Each sample will be retrieved by indexing tensors along the first dimension\n",
        "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader): combines a dataset and a sampler, and provides an iterable over the given dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "_D9Vb4XvkLst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## add batch size to work with mini batch gradient descend\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "gIRRr5PtkAmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## training\n",
        "epochs = 10\n",
        "\n",
        "# create a function to not replicate code\n",
        "def training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size, verbose=1):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # put model in training mode\n",
        "        model.train()\n",
        "\n",
        "        running_train_loss = 0.0\n",
        "        running_train_accuracy = 0.0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # forward pass on train data\n",
        "            y_logits = model(X_batch).squeeze()\n",
        "            y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "            # calculate the loss (use logits to compute loss function)\n",
        "            loss = loss_fn(y_logits, y_batch)\n",
        "\n",
        "            # zero grad of the optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # loss backward\n",
        "            loss.backward()\n",
        "\n",
        "            # progress the optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "            # calculate accuracy for this batch\n",
        "            train_accuracy = get_accuracy(y_pred, y_batch)\n",
        "\n",
        "            # accumulate loss and accuracy for the epoch\n",
        "            running_train_loss += loss.item()\n",
        "            running_train_accuracy += train_accuracy.item()\n",
        "\n",
        "        # average training loss and accuracy over all batches\n",
        "        avg_train_loss = running_train_loss / len(train_loader)\n",
        "        avg_train_accuracy = running_train_accuracy / len(train_loader)\n",
        "\n",
        "        ### Testing\n",
        "\n",
        "        model.eval()\n",
        "        running_test_loss = 0.0\n",
        "        running_test_accuracy = 0.0\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            for X_batch, y_batch in test_loader:\n",
        "                # forward pass on test data\n",
        "                test_pred = model(X_batch).squeeze()\n",
        "\n",
        "                # calculate test loss\n",
        "                test_loss = loss_fn(test_pred, y_batch)\n",
        "\n",
        "                # calculate accuracy for this batch\n",
        "                test_accuracy = get_accuracy(test_pred, y_batch)\n",
        "\n",
        "                # accumulate test loss and accuracy\n",
        "                running_test_loss += test_loss.item()\n",
        "                running_test_accuracy += test_accuracy.item()\n",
        "\n",
        "            # average test loss and accuracy over all batches\n",
        "            avg_test_loss = running_test_loss / len(test_loader)\n",
        "            avg_test_accuracy = running_test_accuracy / len(test_loader)\n",
        "\n",
        "        # print metrics every epoch\n",
        "        if verbose > 0:\n",
        "            print(f\"Epoch: {epoch} | Train Loss={avg_train_loss:.2f} & Accuracy={avg_train_accuracy:.2f}% | \"\n",
        "                  f\"Test Loss={avg_test_loss:.2f} & Accuracy={avg_test_accuracy:.2f}%\\n\")\n",
        "\n",
        "\n",
        "training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size)"
      ],
      "metadata": {
        "id": "6iAD6MNtR1Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs8joodAgpzP"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"1 Hidden layer NN with linear activation\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNa9QE8tgpzP"
      },
      "source": [
        "### Question 1:\n",
        "####  What happens if we change the activation function of the first hidden  layer to `'sigmoid'`?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHiddenNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=input_dim, out_features=3)\n",
        "        self.head_layer = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        out = self.head_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = OneHiddenNN(input_dim=2)\n",
        "model"
      ],
      "metadata": {
        "id": "saa0crCmSqBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "id": "k9Cyj29_Vpyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9vvK99xgpzQ"
      },
      "outputs": [],
      "source": [
        "## define loss and get optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg1JnhIOgpzQ"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"1 Hidden layer NN with sigmoid activation\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QN9ly0UgpzQ"
      },
      "source": [
        "### Question 2:\n",
        "####  What happens if we add more neurons to the first hidden layer ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYbOYWAogpzQ"
      },
      "outputs": [],
      "source": [
        "draw_neural_net(.1, .9, .1, .9, [2, 5, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHiddenNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_neurons):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=input_dim, out_features=hidden_neurons)\n",
        "        self.head_layer = nn.Linear(in_features=hidden_neurons, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        out = self.head_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = OneHiddenNN(input_dim=2, hidden_neurons=5)\n",
        "model"
      ],
      "metadata": {
        "id": "OvqUZsjoV_PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "id": "a93-zugaWMaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjTKWyrWgpzQ"
      },
      "outputs": [],
      "source": [
        "## define loss and get optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ryP6tggpzR"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"1 Hidden layer NN with 5 neurons\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSaa8FqOgpzR"
      },
      "source": [
        "### Question 3:\n",
        "####  What happens if we add one more hidden layer ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K18IIe5rgpzS"
      },
      "outputs": [],
      "source": [
        "draw_neural_net(.1, .9, .1, .9, [2, 3, 3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoHiddenNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_1 = nn.Linear(in_features=input_dim, out_features=3)\n",
        "        self.hidden_layer_2 = nn.Linear(in_features=3, out_features=3)\n",
        "        self.head_layer = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer_1(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        out = self.hidden_layer_2(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        out = self.head_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = TwoHiddenNN(input_dim=2)\n",
        "model"
      ],
      "metadata": {
        "id": "1YKhWI-pXxpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "id": "P0cyHgVAYDcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f71-OsFVgpzS"
      },
      "outputs": [],
      "source": [
        "## define loss and get optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RThGf27gpzS"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"2 Hidden layer NN with 3 neurons\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weLsWg9KgpzS"
      },
      "source": [
        "####  Use  the [hyperbolic tangent](https://mathworld.wolfram.com/HyperbolicTangent.html) activation `'tanh'` with the first simple model and compare the results with the sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHiddenNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_neurons):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=input_dim, out_features=hidden_neurons)\n",
        "        self.head_layer = nn.Linear(in_features=hidden_neurons, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer(x)\n",
        "        out = torch.tanh(out)\n",
        "        out = self.head_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = OneHiddenNN(input_dim=2, hidden_neurons=5)\n",
        "model"
      ],
      "metadata": {
        "id": "k30nCIRKccUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG3LTngrgpzS"
      },
      "outputs": [],
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3omaOeE1gpzS"
      },
      "outputs": [],
      "source": [
        "## define loss and get optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "training_nn(model, train_dataset, test_dataset, loss_fn, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DKLIgFqgpzT"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"2 Hidden layer NN with 3 neurons\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjI94fcZgpzT"
      },
      "source": [
        "## Practice I\n",
        "\n",
        "Repeat the process with a different dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBVPJQ8FgpzT"
      },
      "outputs": [],
      "source": [
        "N = 5000\n",
        "X_np, y_np = sklearn.datasets.make_moons(n_samples=N, noise=.18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEwzDbhvgpzT"
      },
      "outputs": [],
      "source": [
        "# Visualize the data:\n",
        "plt.scatter(X_np[:,0], X_np[:,1], c=y_np.ravel(), s=40, cmap=plt.cm.Spectral);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1QRXfPngpzT"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train_np, X_test_np, y_train_np, y_test_np) = train_test_split(\n",
        "    X_np,\n",
        "    y_np,\n",
        "    test_size=0.2,\n",
        "    random_state=14,\n",
        ")\n",
        "\n",
        "# convert numpy array to tensors\n",
        "\n",
        "X_train = torch.from_numpy(X_train_np).type(torch.float).to(device)\n",
        "X_test = torch.from_numpy(X_test_np).type(torch.float).to(device)\n",
        "y_train = torch.from_numpy(y_train_np).type(torch.float).to(device)\n",
        "y_test = torch.from_numpy(y_test_np).type(torch.float).to(device)\n",
        "\n",
        "print('X shape:{0}, y shape:{1}'.format(X.shape, y.shape))\n",
        "print('X_train shape:{0}, y_train shape:{1}'.format(X_train.size(),\n",
        "                                                    y_train.size()))\n",
        "print('X_test shape:{0}, y_test shape:{1}'.format(X_test.size(), y_test.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgNTgpeHgpzT"
      },
      "source": [
        "### Define your model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SolutionModel(nn.Module):\n",
        "    def __init__(self, ...):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "model = ..."
      ],
      "metadata": {
        "id": "LG7c_hkwfv-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9xXpzjMgpzT"
      },
      "outputs": [],
      "source": [
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(..., input_size=(1, 2), expand_nested=True)\n",
        "model_graph.visual_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7MgXn1vgpzU"
      },
      "outputs": [],
      "source": [
        "## define loss and get optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(params=...)\n",
        "\n",
        "## create your tensor dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = ...\n",
        "training_nn(model, train_dataset, test_dataset, loss, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2Lr5okwgpzU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    y_preds = model(X_test).squeeze()\n",
        "\n",
        "print(f'Test Accuracy: {get_accuracy(y_preds, y_test):.2f}')\n",
        "\n",
        "plot_decision_boundary(model, X_test, y_test)\n",
        "plt.title(\"Solution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential mode\n",
        "\n",
        "There is another way to define the architecture of our neural networks with torch, and that is by using the [sequential module](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential). The output of the previous layer serves as input to the next layer without allowing any distinct execution flow."
      ],
      "metadata": {
        "id": "pE_2tLPF_heg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "\n",
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(input_dim, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 4),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, output_dim)\n",
        ")\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "id": "WVYPQL619LAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbD75w8hgpzW"
      },
      "source": [
        "## Visualize decision boundary by epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62mUY9uZgpzW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIhY3YCugpzW"
      },
      "outputs": [],
      "source": [
        "def plot_save_decision_boundary(model, X, y, epoch, epoch_image):\n",
        "    h = 0.1\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min.to(\"cpu\").numpy(), x_max.to(\"cpu\").numpy(), h),\n",
        "                         np.arange(y_min.to(\"cpu\").numpy(), y_max.to(\"cpu\").numpy(), h))\n",
        "\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    # Convert grid to a torch tensor and make predictions\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
        "        Z = model(grid_tensor).squeeze()\n",
        "        Z = (Z >= 0.5).float().to(\"cpu\").numpy()\n",
        "\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.5, colors=['blue', 'red'], levels=[-0.5, 0.5, 1.5])\n",
        "    X_np = X.to(\"cpu\").numpy()\n",
        "    y_np = y.to(\"cpu\").numpy()\n",
        "    plt.scatter(X_np[y_np == 0][:, 0], X_np[y_np == 0][:, 1], color='blue', label='Class 0', alpha=0.5)\n",
        "    plt.scatter(X_np[y_np == 1][:, 0], X_np[y_np == 1][:, 1], color='red', label='Class 1', alpha=0.5)\n",
        "    plt.title(f'Epoch {epoch}')\n",
        "    plt.savefig(epoch_image)\n",
        "    plt.close()\n",
        "\n",
        "def generate_spiral_dataset(n_points, noise=0.5):\n",
        "    n = np.sqrt(np.random.rand(n_points, 1)) * 780 * (2 * np.pi) / 360\n",
        "    d1x = -np.cos(n) * n + np.random.rand(n_points, 1) * noise\n",
        "    d1y = np.sin(n) * n + np.random.rand(n_points, 1) * noise\n",
        "\n",
        "    X, y = (np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y)))),\n",
        "            np.hstack((np.zeros(n_points), np.ones(n_points))))\n",
        "    return X, y.reshape(-1, 1)\n",
        "\n",
        "n_points = 2500\n",
        "X_np, y_np = generate_spiral_dataset(n_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux1k7-qIgpzW"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_np[y_np[:, 0] == 0][:, 0], X_np[y_np[:, 0] == 0][:, 1], color='blue', label='Class 0')\n",
        "plt.scatter(X_np[y_np[:, 0] == 1][:, 0], X_np[y_np[:, 0] == 1][:, 1], color='red', label='Class 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTfBVeuxgpzW"
      },
      "outputs": [],
      "source": [
        "# Normalize data\n",
        "(X_train_np, X_test_np, y_train_np, y_test_np) = train_test_split(\n",
        "    X_np,\n",
        "    y_np,\n",
        "    test_size=0.3,\n",
        "    random_state=14\n",
        ")\n",
        "\n",
        "# # Apply normalization using sklearn\n",
        "# scaler = StandardScaler()\n",
        "# X_train_np = scaler.fit_transform(X_train_np)\n",
        "# X_test_np = scaler.transform(X_test_np)\n",
        "\n",
        "# convert numpy array to tensors\n",
        "X_train = torch.from_numpy(X_train_np).type(torch.float).to(device)\n",
        "X_test = torch.from_numpy(X_test_np).type(torch.float).to(device)\n",
        "y_train = torch.from_numpy(y_train_np).type(torch.float).to(device).squeeze()\n",
        "y_test = torch.from_numpy(y_test_np).type(torch.float).to(device).squeeze()\n",
        "\n",
        "print('X shape:{0}, y shape:{1}'.format(X_np.shape, y_np.shape))\n",
        "print('X_train shape:{0}, y_train shape:{1}'.format(X_train.size(),\n",
        "                                                    y_train.size()))\n",
        "print('X_test shape:{0}, y_test shape:{1}'.format(X_test.size(), y_test.size()))\n",
        "\n",
        "# replicate standard scaler of sklearn with torch\n",
        "mean = X_train.mean(dim=0)\n",
        "std = X_train.std(dim=0)\n",
        "print(f\"\\nStandardScaler\\nmean={mean} std={std}\")\n",
        "print(f\"Original X_train {X_train[:5]}\")\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "print(f\"Standarized X_train {X_train[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Q4Sk7jgpzX"
      },
      "outputs": [],
      "source": [
        "lr_list = [0.00001, 0.01, 0.1]\n",
        "\n",
        "# define model architecture\n",
        "class LRExperiments(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=input_dim, out_features=16)\n",
        "        self.head_layer = nn.Linear(in_features=16, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.hidden_layer(x)\n",
        "        out = torch.relu(out)\n",
        "        out = self.head_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# Store the models in a list\n",
        "model_dict = {}\n",
        "for i, lr in enumerate(lr_list):\n",
        "  model = LRExperiments(input_dim=2)\n",
        "  model.to(device)\n",
        "  model_dict[f\"model_{i}\"] = {\"model\": model,\n",
        "                              \"loss\": nn.BCEWithLogitsLoss(),\n",
        "                              \"optimizer\": torch.optim.Adam(params=model.parameters(), lr=lr)}\n",
        "\n",
        "n_epochs = 60\n",
        "batch_size = 16\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "epoch_images = {}\n",
        "\n",
        "for i in range(len(model_dict)):\n",
        "  epoch_images[i] = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for ix, (k, v) in enumerate(model_dict.items()):\n",
        "      training_nn(v[\"model\"], train_dataset, test_dataset, v[\"loss\"], v[\"optimizer\"],\n",
        "                  1, batch_size, verbose=0)\n",
        "      epoch_image = f'epoch_{epoch}_{k}.png'\n",
        "      epoch_images[ix].append(epoch_image)\n",
        "\n",
        "      plot_save_decision_boundary(v[\"model\"], X_test, y_test, epoch, epoch_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktlp00sBgpzX"
      },
      "outputs": [],
      "source": [
        "from PIL import Image as Image_PIL\n",
        "\n",
        "# Create the GIF\n",
        "\n",
        "for ix in range(len(model_dict)):\n",
        "  gif_filename = f'epoch_animation_model_{ix}.gif'\n",
        "  images = [Image_PIL.open(epoch_image) for epoch_image in epoch_images[ix]]\n",
        "\n",
        "  duration = 0.15\n",
        "  images[0].save(gif_filename,\n",
        "              format='GIF',\n",
        "              append_images=images[1:],\n",
        "              save_all=True,\n",
        "              duration=duration*1000,\n",
        "              loop=0)\n",
        "\n",
        "  # Delete the individual epoch images\n",
        "  for epoch_image in epoch_images[ix]:\n",
        "      os.remove(epoch_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EFAVWP7gpzX"
      },
      "outputs": [],
      "source": [
        "# Model with LR=0.0001\n",
        "Image(filename='epoch_animation_model_0.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDVgPIdykUW5"
      },
      "outputs": [],
      "source": [
        "# Model with LR=0.01\n",
        "Image(filename='epoch_animation_model_1.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_QzHAi_mivJ"
      },
      "outputs": [],
      "source": [
        "# Model with LR=0.1\n",
        "Image(filename='epoch_animation_model_2.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF62cCjy4j_g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "wRuwL",
      "launcher_item_id": "NI888"
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}